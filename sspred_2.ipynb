{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make a simple protein secondary structure predictor for predicting one of the three classes: coil, helix and beta sheet. Similar to [psipred](http://bioinf.cs.ucl.ac.uk/psipred/), we will use a window of amino acids around a residue and feed it into a neural network, but we will only use one neural network instead of two, and we will use a window of 21, i.e. 10 amino acids to either side of the one to be predicted. \n",
    "<br>\n",
    "<br> We will use a convolutional neural network with dense layers on top, and we will evaluate the quality of the predictions with the Q3 accuracy (basically accuracy across all residues) and the segment of overlap score. The segment of overlap score takes into account how much entire segments with the same secondary structure type overlap between the reference and the prediction, as opposed to the identity of individual amino acids.\n",
    "<br>\n",
    "<br> For training, validation and testing, we will use the data that was used to train the [jpred method](http://www.compbio.dundee.ac.uk/jpred4/about_RETR_JNetv231_details.shtml) as it is easily available and fulfills criteria such as a lack of structural/sequence homology between training and test set, which would lead to a biased evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll load libraries, data and define some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = np.loadtxt('train_names', dtype='str')\n",
    "test_ids = np.loadtxt('test_names', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_items={}\n",
    "for i in train_ids:\n",
    "    with open('data/training/'+i+\".fasta\") as input:\n",
    "        seq = ''\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            if line[0] != '>':\n",
    "                seq += line.strip()\n",
    "    with open('data/training/'+i+\".dssp\") as input:\n",
    "        ss = ''\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            if line[0] != '>':\n",
    "                ss += line.strip()\n",
    "            \n",
    "    training_items[i] = {'seq':seq, 'ss':ss}\n",
    "    \n",
    "    \n",
    "test_items={}\n",
    "for i in test_ids:\n",
    "    with open('data/blind/'+i+\".fasta\") as input:\n",
    "        seq = ''\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            if line[0] != '>':\n",
    "                seq += line.strip()\n",
    "    with open('data/blind/'+i+\".dssp\") as input:\n",
    "        ss = ''\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            if line[0] != '>':\n",
    "                ss += line.strip()\n",
    "            \n",
    "    test_items[i] = {'seq':seq, 'ss':ss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_id_dict = {'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, 'I': 7,\n",
    "              'K': 8, 'L': 9, 'M': 10, 'N': 11, 'P': 12, 'Q': 13, 'R': 14, \n",
    "              'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19}\n",
    "\n",
    "pos_aa_dict = {j:i for i,j in aa_id_dict.items()}\n",
    "\n",
    "ss_id_dict = {'H':0, 'E':1, '-':2}\n",
    "\n",
    "pos_ss_dict = {j:i for i,j in ss_id_dict.items()}\n",
    "\n",
    "def aa_to_onehot(aa_str, aa_to_nr=aa_id_dict, mask=None):\n",
    "    \"\"\"\n",
    "    Onehot encode an amino acid string using a letter to number dictionary.\n",
    "    The mask (from proteinnet files) is used to remove residues missing atoms from the primary sequence.\n",
    "    \"\"\"\n",
    "    if mask!=None:\n",
    "        mask_ind = np.asarray([x=='+' for x in mask])*1\n",
    "        mask_ind = np.nonzero(mask_ind)\n",
    "        aa_str = \"\".join([aa_str[x] for x in mask_ind[0]]) # the mask indices are a list in a list\n",
    "    init_array = np.zeros( (len(aa_to_nr.keys()), len(aa_str)) )\n",
    "    for i,j in enumerate(aa_str):\n",
    "        init_array[aa_to_nr[j], i] = 1\n",
    "    return init_array\n",
    "\n",
    "def label_to_index(ss, id_dict):\n",
    "    labels = np.array([id_dict[i] for i in ss])\n",
    "    return(labels)\n",
    "\n",
    "def onehot_to_str(onehot_arr, map_dict=pos_aa_dict):\n",
    "    '''Helper function to recover aa sequence from onehot encoding\n",
    "        input must be aa*N numpy array'''\n",
    "    aas = []\n",
    "    N = onehot_arr.shape[1]\n",
    "    for i in range(N):\n",
    "        pos = np.where(onehot_arr[:, i]>0)[0]\n",
    "        aas.append(map_dict[int(pos)])\n",
    "    return \"\".join(aas)\n",
    "\n",
    "def filter_proteins(prot_id, seq, allowed_symbols):\n",
    "    allowed = True\n",
    "    for i in seq:\n",
    "        if i not in allowed_symbols:\n",
    "            allowed = False\n",
    "    return allowed\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll filter away proteins with missing/unidentified residues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inds_filt = np.array([filter_proteins(i, training_items[i]['seq'], aa_id_dict.keys()) for i in train_ids])\n",
    "test_inds_filt = np.array([filter_proteins(i, test_items[i]['seq'], aa_id_dict.keys()) for i in test_ids])\n",
    "\n",
    "train_ids_filt = train_ids[train_inds_filt]\n",
    "test_ids_filt = test_ids[test_inds_filt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to pad the sequences on the ends and split them into smaller pieces of equal size for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_and_split_1h(vector, k, map_dict):\n",
    "    padding = np.zeros((len(map_dict.keys()), int((k-1)/2)))\n",
    "    vector_padded = np.concatenate((padding, aa_to_onehot(vector, map_dict), padding), axis=1)\n",
    "    sub_arrays = []\n",
    "    for i in range(int((k-1)/2), len(vector)+int((k-1)/2)):\n",
    "        sub_arr = vector_padded[:, i-int((k-1)/2):i+int((k-1)/2)+1]\n",
    "        sub_arrays.append(sub_arr)\n",
    "    sub_arrays = np.array(sub_arrays)\n",
    "    return torch.tensor(sub_arrays).float()\n",
    "\n",
    "def tensorize_ss(ss, map_dict=ss_id_dict, tensorize=True):\n",
    "    if tensorize:\n",
    "        tensor = torch.tensor(label_to_index(ss, map_dict))\n",
    "    else:\n",
    "        tensor = label_to_index(ss, map_dict)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_window = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_ids_filt:\n",
    "    training_items[i]['seq_1h'] = pad_and_split_1h(training_items[i]['seq'], k_window, aa_id_dict)\n",
    "    \n",
    "for i in test_ids_filt:\n",
    "    test_items[i]['seq_1h'] = pad_and_split_1h(test_items[i]['seq'], k_window, aa_id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(678)\n",
    "inds_perm = np.random.permutation(len(train_ids_filt))\n",
    "val_prots = train_ids_filt[inds_perm[0:int(np.floor(len(inds_perm)*0.2))]]\n",
    "train_prots = train_ids_filt[inds_perm[int(np.floor(len(inds_perm)*0.2)):]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq_tensor = torch.cat([training_items[i]['seq_1h'] for i in train_prots])\n",
    "train_ss_tensor = torch.cat([tensorize_ss(training_items[i]['ss']) for i in train_prots])\n",
    "\n",
    "val_seq_tensor = torch.cat([training_items[i]['seq_1h'] for i in val_prots])\n",
    "val_ss_tensor = torch.cat([tensorize_ss(training_items[i]['ss']) for i in val_prots])\n",
    "\n",
    "test_seq_tensor = torch.cat([test_items[i]['seq_1h'] for i in test_ids_filt])\n",
    "test_ss_tensor = torch.cat([tensorize_ss(test_items[i]['ss']) for i in test_ids_filt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([176746, 20, 21])\n",
      "torch.Size([41033, 20, 21])\n",
      "torch.Size([22734, 20, 21])\n"
     ]
    }
   ],
   "source": [
    "print(train_seq_tensor.shape)\n",
    "print(val_seq_tensor.shape)\n",
    "print(test_seq_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class proteindataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, seqs, ss):\n",
    "        self.sequences = seqs\n",
    "        self.ss = ss\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ss)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.sequences[idx,:, :], self.ss[idx]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = proteindataset(train_seq_tensor, train_ss_tensor)\n",
    "val_dataset = proteindataset(val_seq_tensor, val_ss_tensor)\n",
    "test_dataset = proteindataset(test_seq_tensor, test_ss_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=100,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=1000,\n",
    "                                         shuffle=False, num_workers=4)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=100,\n",
    "                                         shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv0 = nn.Conv1d(20, 32, kernel_size=3)\n",
    "        self.conv0_bn = torch.nn.BatchNorm1d(32)\n",
    "        self.conv1 = nn.Conv1d(32, 64, kernel_size=2) # down\n",
    "        self.conv1_bn = torch.nn.BatchNorm1d(64)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3) # down \n",
    "        self.conv2_bn = torch.nn.BatchNorm1d(128)\n",
    "        self.fc1 = nn.Linear(128, 8)\n",
    "        self.fc2 = nn.Linear(8, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv0_out = self.conv0_bn(self.pool(F.relu(self.conv0(x))))\n",
    "        conv1_out = self.conv1_bn(self.pool(F.relu(self.conv1(conv0_out))))\n",
    "        conv2_out = self.conv2_bn(self.pool(F.relu(self.conv2(conv1_out))))\n",
    "        conv2_out = conv2_out.view(-1, 128*1)\n",
    "        fc1_out = F.relu(self.fc1(conv2_out))\n",
    "        fc2_out = F.relu(self.fc2(fc1_out))\n",
    "\n",
    "        return fc2_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iteration: 588] training loss: 1.0168877528357385, validation_loss: 0.9291604061921436\n",
      "epoch: 0, iteration: 1177] training loss: 0.892276327051412, validation_loss: 0.8604613131000881\n",
      "new best validation loss, saving..\n",
      "epoch: 0, iteration: 1766] training loss: 0.8447460362178563, validation_loss: 0.826155689500627\n",
      "new best validation loss, saving..\n",
      "epoch: 1, iteration: 588] training loss: 0.8117086127375099, validation_loss: 0.8025993101653598\n",
      "new best validation loss, saving..\n",
      "epoch: 1, iteration: 1177] training loss: 0.7843401534245658, validation_loss: 0.7888404528299968\n",
      "new best validation loss, saving..\n",
      "epoch: 1, iteration: 1766] training loss: 0.7732287105963469, validation_loss: 0.7764095181510562\n",
      "new best validation loss, saving..\n",
      "epoch: 2, iteration: 588] training loss: 0.7531477830203563, validation_loss: 0.7683014004003436\n",
      "new best validation loss, saving..\n",
      "epoch: 2, iteration: 1177] training loss: 0.7469049677480462, validation_loss: 0.761275040251868\n",
      "new best validation loss, saving..\n",
      "epoch: 2, iteration: 1766] training loss: 0.7433111370115815, validation_loss: 0.757630339690617\n",
      "new best validation loss, saving..\n",
      "epoch: 3, iteration: 588] training loss: 0.7247657346806421, validation_loss: 0.7566155124278298\n",
      "new best validation loss, saving..\n",
      "epoch: 3, iteration: 1177] training loss: 0.7274889210286488, validation_loss: 0.7550452663784933\n",
      "new best validation loss, saving..\n",
      "epoch: 3, iteration: 1766] training loss: 0.72779361086507, validation_loss: 0.7527667922633036\n",
      "new best validation loss, saving..\n",
      "epoch: 4, iteration: 588] training loss: 0.713973983135612, validation_loss: 0.7498710893449329\n",
      "new best validation loss, saving..\n",
      "epoch: 4, iteration: 1177] training loss: 0.7124047388649958, validation_loss: 0.7477676499457585\n",
      "new best validation loss, saving..\n",
      "epoch: 4, iteration: 1766] training loss: 0.7129166084760721, validation_loss: 0.7472611310936157\n",
      "new best validation loss, saving..\n",
      "epoch: 5, iteration: 588] training loss: 0.7008231760386903, validation_loss: 0.7504889411585672\n",
      "epoch: 5, iteration: 1177] training loss: 0.7035987233467944, validation_loss: 0.7468235066958836\n",
      "new best validation loss, saving..\n",
      "epoch: 5, iteration: 1766] training loss: 0.7010112104270171, validation_loss: 0.7441599269707997\n",
      "new best validation loss, saving..\n",
      "epoch: 6, iteration: 588] training loss: 0.6900480121424728, validation_loss: 0.7478803878738765\n",
      "epoch: 6, iteration: 1177] training loss: 0.6929523211181265, validation_loss: 0.7472900847593942\n",
      "epoch: 6, iteration: 1766] training loss: 0.6938651469243605, validation_loss: 0.7466080586115517\n",
      "epoch: 7, iteration: 588] training loss: 0.6841559597308445, validation_loss: 0.7498516695840022\n",
      "epoch: 7, iteration: 1177] training loss: 0.682591842927026, validation_loss: 0.7460034234183176\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "prints_per_epoch = 3\n",
    "\n",
    "verbose_k = np.floor(len(trainloader)/prints_per_epoch)\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "iterations = []\n",
    "best_loss = None\n",
    "patience_val = 5\n",
    "patience_counter = patience_val\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        sequence, ss = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        predicted_angles = net(sequence)\n",
    "\n",
    "        loss = criterion(predicted_angles, ss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # adding to running loss, we will output this at every verbose_k\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % verbose_k == 0:\n",
    "            if patience_counter < 1:\n",
    "                break\n",
    "            train_losses.append(running_loss/verbose_k)\n",
    "            true_iter = len(trainloader)*epoch + i\n",
    "            iterations.append(true_iter)\n",
    "            net.eval()\n",
    "            validation_loss = 0\n",
    "            for j in valloader:\n",
    "                pred_k = net(j[0])\n",
    "                loss_k = criterion(pred_k, j[1]).item()\n",
    "                validation_loss += loss_k/len(valloader)\n",
    "            val_losses.append(validation_loss)\n",
    "            net.train()\n",
    "            print('epoch: {}, iteration: {}] training loss: {}, validation_loss: {}'.format(\n",
    "                epoch, i, running_loss/verbose_k, validation_loss))\n",
    "\n",
    "            if best_loss == None:\n",
    "                best_loss = validation_loss\n",
    "            else:\n",
    "                if validation_loss <= min(val_losses):\n",
    "                    patience_counter = patience_val\n",
    "                    print('new best validation loss, saving..')\n",
    "                    best_loss = validation_loss\n",
    "                    torch.save(net.state_dict(), 'cnn_params.pt')\n",
    "                else:\n",
    "                    patience_counter -= 1\n",
    "            \n",
    "\n",
    "            running_loss = 0.0\n",
    "            \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('/Users/Deathvoodoo/big_folders_docs/ss_pred/cnn_params.pt'))\n",
    "\n",
    "net.eval()\n",
    "\n",
    "validation_preds = np.concatenate([np.apply_along_axis(np.argmax, 1, net(i[0]).detach().numpy()) for i in valloader])\n",
    "validation_reals = [tensorize_ss(training_items[i]['ss'], ss_id_dict, tensorize=False) for i in val_prots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(iterations, train_losses, label='train loss')\n",
    "plt.scatter(iterations, val_losses, label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to reconstruct the outputs into vectors corresponding to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_predictions(preds, real_vectors):\n",
    "    preds_rec = []\n",
    "    cur_idx = 0\n",
    "    for i in real_vectors:\n",
    "        assembled = preds[cur_idx:cur_idx+len(i)]\n",
    "        preds_rec.append(assembled)\n",
    "        cur_idx += len(i)\n",
    "    return preds_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_preds_rec = reconstruct_predictions(validation_preds, validation_reals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate the results with Q3 accuracy and segment of overlap. We'll start with the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_acc(real, pred):\n",
    "    if real.shape[0] == 1:\n",
    "        real = np.squeeze(real, 0)\n",
    "    if pred.shape[0] == 1:\n",
    "        pred = np.squeeze(pred, 0)   \n",
    "    return np.sum(real==pred)/real.shape[0]\n",
    "\n",
    "\n",
    "def segment_of_overlap(ss_ref_str, ss_pred_str):\n",
    "    ss_ref = get_segments(ss_ref_str)\n",
    "    ss_pred = get_segments(ss_pred_str)\n",
    "    val_total = 0\n",
    "    N_total = 0\n",
    "    for k in ss_ref.keys():\n",
    "        subsum_k = 0\n",
    "        N_k = 0\n",
    "        for i in ss_ref[k]:\n",
    "            l_s1 = len(i[1])\n",
    "            N_k += l_s1\n",
    "            for j in ss_pred[k]:\n",
    "                l_s2 = len(j[1])\n",
    "                minov = len(np.intersect1d(i[1], j[1]))\n",
    "                if minov > 0:\n",
    "                    maxov = len(np.union1d(i[1], j[1]))\n",
    "                    delta = np.min([maxov-minov, minov, np.floor(l_s1/2), np.floor(l_s2/2)])\n",
    "                    value = l_s1*(minov+delta)/maxov\n",
    "                    subsum_k += value\n",
    "        N_total += N_k\n",
    "        val_total += subsum_k\n",
    "    sov = val_total/N_total\n",
    "    return sov\n",
    "\n",
    "def get_segments(ss_str):\n",
    "    ss_strs = [\"\".join(grp) for val, grp in itertools.groupby(ss_str)]\n",
    "    idx_lens = []\n",
    "    idx_start = 0\n",
    "    for i in ss_strs:\n",
    "        idx_lens.append(np.arange(idx_start, idx_start+len(i)))\n",
    "        idx_start += len(i)\n",
    "    segment_types = {'E':[], 'H':[], '-':[]}\n",
    "    for i in range(len(ss_strs)):\n",
    "        segment_types[ss_strs[i][0]].append([ss_strs[i], idx_lens[i]])\n",
    "    return segment_types\n",
    "\n",
    "def ints_to_symbols1d(ss_arr, map_dict=pos_ss_dict):\n",
    "    if len(ss_arr.shape) > 1:\n",
    "        for i,j in enumerate(ss_arr.shape):\n",
    "            if j == 1:\n",
    "                ss_arr = np.squeeze(ss_arr, i)\n",
    "    return \"\".join([map_dict[i] for i in ss_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN validation Q3 accuracy:  0.6753099947962968\n"
     ]
    }
   ],
   "source": [
    "val_accuracies = [q3_acc(i,j) for i,j in zip(validation_preds_rec, validation_reals)]\n",
    "print('CNN validation Q3 accuracy: ', np.mean(val_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're not really going to search for any hyperparameters, we can just evaluate the test set and also compare with psipred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.concatenate([np.apply_along_axis(np.argmax, 1, net(i[0]).detach().numpy()) for i in testloader])\n",
    "test_reals = [tensorize_ss(test_items[i]['ss'], ss_id_dict, tensorize=False) for i in test_ids_filt]\n",
    "test_preds_rec = reconstruct_predictions(test_preds, test_reals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracies_cnn =[q3_acc(i,j) for i,j in zip(test_preds_rec, test_reals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_psipred(prot_id, letter_to_number=ss_id_dict):\n",
    "    ss = ''\n",
    "    with open('/Users/Deathvoodoo/big_folders_docs/ss_pred/ss_predictions_psipred/{}.horiz'.format(prot_id)) as input:\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            line = line.split()\n",
    "            if len(line)>0:\n",
    "                if line[0] == 'Pred:' and len(line)>1:\n",
    "                    ss += line[1]\n",
    "\n",
    "    ss = ss.replace('C', '-') # psipred predictions use C instead of - for non sheet/helix\n",
    "    ss = np.array([letter_to_number[i] for i in ss])\n",
    "    return ss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "psipred_preds = [parse_psipred(i) for i in test_ids_filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "psipred_acc = [q3_acc(i,j) for i,j in zip(psipred_preds, test_reals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Q3 accuracy:  0.6730800099449464\n",
      "psipred Q3 accuracy:  0.7255188449781512\n"
     ]
    }
   ],
   "source": [
    "print('CNN Q3 accuracy on test set: ',np.mean(test_accuracies_cnn))\n",
    "print('psipred Q3 accuracy on test set: ',np.mean(psipred_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check segment of overlap score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_str_cnn = [ints_to_symbols1d(i) for i in test_preds_rec]\n",
    "test_preds_str_psipred = [ints_to_symbols1d(i) for i in psipred_preds]\n",
    "test_reals_str = [ints_to_symbols1d(i) for i in test_reals] # same as grabbing strings directly from the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN SOV:  0.7172306616025629\n",
      "psipred SOV:  0.7850154998573716\n"
     ]
    }
   ],
   "source": [
    "test_sovs_cnn = [segment_of_overlap(i, j) for i,j in zip(test_preds_str_cnn, test_reals_str)]\n",
    "test_sovs_psipred = [segment_of_overlap(i, j) for i,j in zip(test_preds_str_psipred, test_reals_str)]\n",
    "\n",
    "print('CNN SOV on test set: ', np.mean(test_sovs_cnn))\n",
    "print('psipred SOV on test set: ', np.mean(test_sovs_psipred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bitdff059f72f8b417fb86b0d43a0194990"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
