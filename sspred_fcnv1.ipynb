{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make a simple protein secondary structure predictor for predicting one of the three classes: coil, helix and beta sheet. Whereas popular tools like [psipred](http://bioinf.cs.ucl.ac.uk/psipred/) use neural networks on a window of amino acids, we will instead use a fully convolutional neural network to input the whole sequence. \n",
    "<brb>\n",
    "Thus, the input will be sequences encoded as $N*C*L$ where $C$ = 20 (number of amino acids), $L$ = length and $N$ is the size of the minibatch, and the output will have the same dimensions except only three channels, corresponding to one of the three classes. The sequences will be encoded as $N*C*L$ where $C$ = 20 (number of amino acids) and $L$ = length.\n",
    "<br>\n",
    "<br> \n",
    "we will evaluate the quality of the predictions with the Q3 accuracy (basically accuracy across all residues) and the segment of overlap score. The segment of overlap score takes into account how much entire segments with the same secondary structure type overlap between the reference and the prediction, as opposed to the identity of individual amino acids. \n",
    "<br>In order to have an idea of how well we're doing, we will compare our results with the results obtained with psipred, although ideally we're not supposed to use single sequences for psipred, but a multiple sequence alignment.\n",
    "<br>\n",
    "<br> For training, validation and testing, we will use the data that was used to train the [jpred method](http://www.compbio.dundee.ac.uk/jpred4/about_RETR_JNetv231_details.shtml) as it is easily available and fulfills criteria such as a lack of structural/sequence homology between training and test set, which would lead to a biased evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = np.loadtxt('train_names', dtype='str')\n",
    "test_ids = np.loadtxt('test_names', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_items={}\n",
    "for i in train_ids:\n",
    "    with open('data/training/'+i+\".fasta\") as input:\n",
    "        seq = ''\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            if line[0] != '>':\n",
    "                seq += line.strip()\n",
    "    with open('data/training/'+i+\".dssp\") as input:\n",
    "        ss = ''\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            if line[0] != '>':\n",
    "                ss += line.strip()\n",
    "            \n",
    "    training_items[i] = {'seq':seq, 'ss':ss}\n",
    "    \n",
    "    \n",
    "test_items={}\n",
    "for i in test_ids:\n",
    "    with open('data/blind/'+i+\".fasta\") as input:\n",
    "        seq = ''\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            if line[0] != '>':\n",
    "                seq += line.strip()\n",
    "    with open('data/blind/'+i+\".dssp\") as input:\n",
    "        ss = ''\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            if line[0] != '>':\n",
    "                ss += line.strip()\n",
    "            \n",
    "    test_items[i] = {'seq':seq, 'ss':ss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_id_dict = {'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, 'I': 7,\n",
    "              'K': 8, 'L': 9, 'M': 10, 'N': 11, 'P': 12, 'Q': 13, 'R': 14, \n",
    "              'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19}\n",
    "\n",
    "pos_aa_dict = {j:i for i,j in aa_id_dict.items()}\n",
    "\n",
    "ss_id_dict = {'H':0, 'E':1, '-':2}\n",
    "\n",
    "pos_ss_dict = {j:i for i,j in ss_id_dict.items()}\n",
    "\n",
    "def aa_to_onehot(aa_str, aa_to_nr=aa_id_dict, mask=None):\n",
    "    \"\"\"\n",
    "    Onehot encode an amino acid string using a letter to number dictionary.\n",
    "    The mask (from proteinnet files) is used to remove residues missing atoms from the primary sequence.\n",
    "    \"\"\"\n",
    "    if mask!=None:\n",
    "        mask_ind = np.asarray([x=='+' for x in mask])*1\n",
    "        mask_ind = np.nonzero(mask_ind)\n",
    "        aa_str = \"\".join([aa_str[x] for x in mask_ind[0]]) # the mask indices are a list in a list\n",
    "    init_array = np.zeros( (len(aa_to_nr.keys()), len(aa_str)) )\n",
    "    for i,j in enumerate(aa_str):\n",
    "        init_array[aa_to_nr[j], i] = 1\n",
    "    return init_array\n",
    "\n",
    "def label_to_index(ss, id_dict):\n",
    "    labels = np.array([id_dict[i] for i in ss])\n",
    "    return(labels)\n",
    "\n",
    "def onehot_to_str(onehot_arr, map_dict=pos_aa_dict):\n",
    "    '''Helper function to recover aa sequence from onehot encoding\n",
    "        input must be aa*N numpy array'''\n",
    "    aas = []\n",
    "    N = onehot_arr.shape[1]\n",
    "    for i in range(N):\n",
    "        pos = np.where(onehot_arr[:, i]>0)[0]\n",
    "        aas.append(map_dict[int(pos)])\n",
    "    return \"\".join(aas)\n",
    "\n",
    "def filter_proteins(prot_id, seq, allowed_symbols):\n",
    "    allowed = True\n",
    "    for i in seq:\n",
    "        if i not in allowed_symbols:\n",
    "            allowed = False\n",
    "    return allowed\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inds_filt = np.array([filter_proteins(i, training_items[i]['seq'], aa_id_dict.keys()) for i in train_ids])\n",
    "test_inds_filt = np.array([filter_proteins(i, test_items[i]['seq'], aa_id_dict.keys()) for i in test_ids])\n",
    "\n",
    "train_ids_filt = train_ids[train_inds_filt]\n",
    "test_ids_filt = test_ids[test_inds_filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1345,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids_filt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_ids_filt:\n",
    "    training_items[i]['seq_1h'] = aa_to_onehot(training_items[i]['seq'], aa_id_dict)[np.newaxis, :, :]\n",
    "    training_items[i]['ss_1h'] = aa_to_onehot(training_items[i]['ss'], ss_id_dict)[np.newaxis, :, :]\n",
    "    \n",
    "for i in test_ids_filt:\n",
    "    test_items[i]['seq_1h'] = aa_to_onehot(test_items[i]['seq'], aa_id_dict)[np.newaxis, :, :]\n",
    "    test_items[i]['ss_1h'] = aa_to_onehot(test_items[i]['ss'], ss_id_dict)[np.newaxis, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(678)\n",
    "inds_perm = np.random.permutation(len(train_ids_filt))\n",
    "val_prots = train_ids_filt[inds_perm[0:int(np.floor(len(inds_perm)*0.2))]]\n",
    "train_prots = train_ids_filt[inds_perm[int(np.floor(len(inds_perm)*0.2)):]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class proteindataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, seqs, ss):\n",
    "        self.sequences = seqs\n",
    "        self.ss = ss\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.sequences[idx], self.ss[idx]]\n",
    "\n",
    "def protein_collate(batch):\n",
    "    seqs = [item[0] for item in batch]\n",
    "    ss = [item[1] for item in batch]\n",
    "    max_len = max([x.shape[2] for x in seqs])\n",
    "    for i in range(len(batch)):\n",
    "        curr_len = seqs[i].shape[2]\n",
    "        seq_padded = np.pad(seqs[i], ((0,0 ), (0,0), (0,max_len-curr_len)), constant_values = 0)\n",
    "        ss_padded = np.pad(ss[i], ((0,0 ), (0,0), (0,max_len-curr_len)), constant_values = 0)\n",
    "        seqs[i] = torch.tensor(seq_padded).float()\n",
    "        ss[i] = torch.tensor(ss_padded).float()\n",
    "    seq_tensor = torch.cat(seqs, 0)\n",
    "    ss_tensor = torch.cat(ss, 0)\n",
    "    return [seq_tensor, ss_tensor]\n",
    "\n",
    "def protein_collate2(batch):\n",
    "    seqs = [item[0] for item in batch]\n",
    "    ss = [item[1] for item in batch]\n",
    "    max_len = max([x.shape[2] for x in seqs])\n",
    "    for i in range(len(batch)):\n",
    "        curr_len = seqs[i].shape[2]\n",
    "        seq_padded = np.pad(seqs[i], ((0,0 ), (0,0), (0,max_len-curr_len)), constant_values = 0)\n",
    "        ss_padded = np.pad(ss[i], ((0,0 ), (0,max_len-curr_len)), constant_values = 0)\n",
    "        seqs[i] = torch.tensor(seq_padded).float()\n",
    "        ss[i] = torch.tensor(ss_padded).float()\n",
    "    seq_tensor = torch.cat(seqs, 0)\n",
    "    ss_tensor = torch.cat(ss, 0)\n",
    "    return [seq_tensor, ss_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs = [training_items[i]['seq_1h'] for i in train_prots]\n",
    "train_ss = [training_items[i]['ss_1h'] for i in train_prots]\n",
    "\n",
    "val_seqs = [training_items[i]['seq_1h'] for i in val_prots]\n",
    "val_ss = [training_items[i]['ss_1h'] for i in val_prots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = proteindataset(train_seqs, train_ss)\n",
    "val_dataset = proteindataset(val_seqs, val_ss)\n",
    "test_dataset = proteindataset([test_items[i]['seq_1h'] for i in test_items.keys()], [test_items[i]['ss_1h'] for i in test_items.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 89)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ss[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2, collate_fn=protein_collate)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=4, collate_fn=protein_collate)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=4, collate_fn=protein_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "kd2 = 3\n",
    "pad2 = int((kd2-1)/2)\n",
    "kd3 = 5\n",
    "pad3 = int((kd3-1)/2)\n",
    "kd4 = 7\n",
    "pad4 = int((kd4-1)/2)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv0 = nn.Conv1d(20, 32, kernel_size=1)\n",
    "        self.conv0_bn = torch.nn.BatchNorm1d(32)\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=kd2, padding=pad2) # down\n",
    "        self.conv1_bn = torch.nn.BatchNorm1d(32)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=kd3, padding=pad3) # down \n",
    "        self.conv2_bn = torch.nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 64, kernel_size=kd4, padding=pad4) # down\n",
    "        self.conv3_bn = torch.nn.BatchNorm1d(64)\n",
    "        self.conv4 = nn.Conv1d(64, 128, kernel_size=1)\n",
    "        self.conv4_bn = torch.nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.deconv1 = nn.ConvTranspose1d(in_channels=128, out_channels=64, kernel_size=kd4, padding=pad4) # up\n",
    "        self.deconv1_bn = torch.nn.BatchNorm1d(64)\n",
    "        self.conv5 = nn.Conv1d(64, 64, 1)\n",
    "        self.conv5_bn = torch.nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.deconv2 = nn.ConvTranspose1d(in_channels=128, out_channels=64, kernel_size=kd3, padding=pad3) # up\n",
    "        self.deconv2_bn = torch.nn.BatchNorm1d(64)\n",
    "        self.conv6 = nn.Conv1d(64, 64, 1)\n",
    "        self.conv6_bn = torch.nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.deconv3 = nn.ConvTranspose1d(in_channels=96, out_channels=32, kernel_size=kd2, padding=pad2) # up\n",
    "        self.deconv3_bn = torch.nn.BatchNorm1d(32)\n",
    "        self.conv7 = nn.Conv1d(32, 16, (1))\n",
    "        self.conv7_bn = torch.nn.BatchNorm1d(16)\n",
    "        self.conv8 = nn.Conv1d(16, 3, 1)\n",
    "        self.conv8_bn = torch.nn.BatchNorm1d(3)\n",
    "        self.conv9 = nn.Conv1d(3, 3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv0_out = F.relu(self.conv0_bn(self.conv0(x)))\n",
    "        conv1_out = F.relu(self.conv1_bn(self.conv1(conv0_out)))\n",
    "        conv2_out = F.relu(self.conv2_bn(self.conv2(conv1_out)))\n",
    "        conv3_out = F.relu(self.conv3_bn(self.conv3(conv2_out)))\n",
    "        conv4_out = F.relu(self.conv4_bn(self.conv4(conv3_out)))\n",
    "\n",
    "        deconv1_out = F.relu(self.deconv1_bn(self.deconv1(conv4_out)))\n",
    "        conv5_out = F.relu(self.conv5_bn(self.conv5(deconv1_out)))\n",
    "        \n",
    "        deconv2_input = torch.cat((conv2_out, deconv1_out), 1)  \n",
    "        deconv2_out = F.relu(self.deconv2_bn(self.deconv2(deconv2_input)))\n",
    "        conv6_out = F.relu(self.conv6_bn(self.conv6(deconv2_out)))\n",
    "        \n",
    "        deconv3_input = torch.cat((conv1_out, deconv2_out), 1)\n",
    "        deconv3_out = F.relu(self.deconv3_bn(self.deconv3(deconv3_input)))\n",
    "        conv7_out = F.relu(self.conv7_bn(self.conv7(deconv3_out)))\n",
    "        conv8_out = F.relu(self.conv8(conv7_out))\n",
    "        conv9_out = self.conv9(conv8_out)\n",
    "        return conv9_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the network. Note that instead of regular cross entropy we can also use the [dice loss](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient).\n",
    "<br>\n",
    "Conveniently, other people [(e.g. this person)](https://github.com/hubutui/DiceLoss-PyTorch/blob/master/loss.py) have already implemented this loss function with pytorch API and we can simply copy paste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iteration: 88] training loss: 0.7762217481484573, validation_loss: 0.6942470375046857\n",
      "epoch: 0, iteration: 177] training loss: 0.7429212733600916, validation_loss: 0.6735601151521318\n",
      "new best validation loss, saving..\n",
      "epoch: 0, iteration: 266] training loss: 0.7308465664306384, validation_loss: 0.6626881343281399\n",
      "new best validation loss, saving..\n",
      "epoch: 1, iteration: 88] training loss: 0.7209904254152534, validation_loss: 0.6548526151915908\n",
      "new best validation loss, saving..\n",
      "epoch: 1, iteration: 177] training loss: 0.7197424434543995, validation_loss: 0.6590756360704566\n",
      "epoch: 1, iteration: 266] training loss: 0.7175098309356175, validation_loss: 0.6472586758961023\n",
      "new best validation loss, saving..\n",
      "epoch: 2, iteration: 88] training loss: 0.7122096486305922, validation_loss: 0.6418313254432614\n",
      "new best validation loss, saving..\n",
      "epoch: 2, iteration: 177] training loss: 0.7103568590089177, validation_loss: 0.6424324810504906\n",
      "epoch: 2, iteration: 266] training loss: 0.7116796689087086, validation_loss: 0.6518004750452078\n",
      "epoch: 3, iteration: 88] training loss: 0.6997711363803135, validation_loss: 0.6509927116805292\n",
      "epoch: 3, iteration: 177] training loss: 0.7022850694281332, validation_loss: 0.6519272101412922\n",
      "epoch: 3, iteration: 266] training loss: 0.7028521473488111, validation_loss: 0.6372337332445449\n",
      "new best validation loss, saving..\n",
      "epoch: 4, iteration: 88] training loss: 0.6930990132053246, validation_loss: 0.6451951587731952\n",
      "epoch: 4, iteration: 177] training loss: 0.6892132839460051, validation_loss: 0.6589214841672477\n",
      "epoch: 4, iteration: 266] training loss: 0.6964442743344254, validation_loss: 0.6655367513128373\n",
      "epoch: 5, iteration: 88] training loss: 0.7006172865964053, validation_loss: 0.6512669635084927\n",
      "epoch: 5, iteration: 177] training loss: 0.6864785699362166, validation_loss: 0.6511778397187868\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "\n",
    "class BinaryDiceLoss(nn.Module):\n",
    "    \"\"\"Dice loss of binary class\n",
    "    Args:\n",
    "        smooth: A float number to smooth loss, and avoid NaN error, default: 1\n",
    "        p: Denominator value: \\sum{x^p} + \\sum{y^p}, default: 2\n",
    "        predict: A tensor of shape [N, *]\n",
    "        target: A tensor of shape same with predict\n",
    "        reduction: Reduction method to apply, return mean over batch if 'mean',\n",
    "            return sum if 'sum', return a tensor of shape [N,] if 'none'\n",
    "    Returns:\n",
    "        Loss tensor according to arg reduction\n",
    "    Raise:\n",
    "        Exception if unexpected reduction\n",
    "    \"\"\"\n",
    "    def __init__(self, smooth=1, p=2, reduction='mean'):\n",
    "        super(BinaryDiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.p = p\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, predict, target):\n",
    "        assert predict.shape[0] == target.shape[0], \"predict & target batch size don't match\"\n",
    "        predict = predict.contiguous().view(predict.shape[0], -1)\n",
    "        target = target.contiguous().view(target.shape[0], -1)\n",
    "\n",
    "        num = torch.sum(torch.mul(predict, target), dim=1) + self.smooth\n",
    "        den = torch.sum(predict.pow(self.p) + target.pow(self.p), dim=1) + self.smooth\n",
    "\n",
    "        loss = 1 - num / den\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        elif self.reduction == 'none':\n",
    "            return loss\n",
    "        else:\n",
    "            raise Exception('Unexpected reduction {}'.format(self.reduction))\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice loss, need one hot encode input\n",
    "    Args:\n",
    "        weight: An array of shape [num_classes,]\n",
    "        ignore_index: class index to ignore\n",
    "        predict: A tensor of shape [N, C, *]\n",
    "        target: A tensor of same shape with predict\n",
    "        other args pass to BinaryDiceLoss\n",
    "    Return:\n",
    "        same as BinaryDiceLoss\n",
    "    \"\"\"\n",
    "    def __init__(self, weight=None, ignore_index=None, **kwargs):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.kwargs = kwargs\n",
    "        self.weight = weight\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, predict, target):\n",
    "        #print(predict.shape, target.shape)\n",
    "        assert predict.shape == target.shape, 'predict & target shape do not match'\n",
    "        dice = BinaryDiceLoss(**self.kwargs)\n",
    "        total_loss = 0\n",
    "        predict = F.softmax(predict, dim=1)\n",
    "\n",
    "        for i in range(target.shape[1]):\n",
    "            if i != self.ignore_index:\n",
    "                dice_loss = dice(predict[:, i], target[:, i])\n",
    "                if self.weight is not None:\n",
    "                    assert self.weight.shape[0] == target.shape[1], \\\n",
    "                        'Expect weight shape [{}], get[{}]'.format(target.shape[1], self.weight.shape[0])\n",
    "                    dice_loss *= self.weights[i]\n",
    "                total_loss += dice_loss\n",
    "\n",
    "        return total_loss/target.shape[1]\n",
    "\n",
    "criterion = DiceLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "prints_per_epoch = 3\n",
    "\n",
    "verbose_k = np.floor(len(trainloader)/prints_per_epoch)\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "iterations = []\n",
    "best_loss = None\n",
    "patience_val = 5\n",
    "patience_counter = patience_val\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        sequence, true_angles = data\n",
    "        #print(sequence.shape, true_angles.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        predicted_angles = net(sequence)\n",
    "\n",
    "        loss = criterion(predicted_angles, true_angles)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # adding to running loss, we will output this at every verbose_k\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % verbose_k == 0:\n",
    "            if patience_counter < 1:\n",
    "                break\n",
    "            train_losses.append(running_loss/verbose_k)\n",
    "            true_iter = len(trainloader)*epoch + i\n",
    "            iterations.append(true_iter)\n",
    "            net.eval()\n",
    "            validation_loss = 0\n",
    "            for j in valloader:\n",
    "                pred_k = net(j[0])\n",
    "                loss_k = criterion(pred_k, j[1]).item()\n",
    "                validation_loss += loss_k/len(val_seqs)\n",
    "            val_losses.append(validation_loss)\n",
    "            net.train()\n",
    "            print('epoch: {}, iteration: {}] training loss: {}, validation_loss: {}'.format(\n",
    "                epoch, i, running_loss/verbose_k, validation_loss))\n",
    "\n",
    "            if best_loss == None:\n",
    "                best_loss = validation_loss\n",
    "            else:\n",
    "                if validation_loss <= min(val_losses):\n",
    "                    patience_counter = patience_val\n",
    "                    print('new best validation loss, saving..')\n",
    "                    best_loss = validation_loss\n",
    "                    torch.save(net.state_dict(), 'fcn_param_dice.pt')\n",
    "                else:\n",
    "                    patience_counter -= 1\n",
    "            \n",
    "\n",
    "            running_loss = 0.0\n",
    "            \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('/Users/Deathvoodoo/big_folders_docs/ss_pred/fcn_param_dice.pt'))\n",
    "\n",
    "net.eval()\n",
    "\n",
    "validation_preds = [np.apply_along_axis(np.argmax, 1, net(i[0]).detach().numpy()) for i in valloader]\n",
    "#validation_reals = [np.apply_along_axis(np.argmax, 1, i[1].detach().numpy()) for i in valloader]\n",
    "validation_reals = [np.apply_along_axis(np.argmax, 1, i) for i in val_ss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 507)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(iterations, train_losses, label='train loss')\n",
    "plt.scatter(iterations, val_losses, label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_acc(real, pred):\n",
    "    if real.shape[0] == 1:\n",
    "        real = np.squeeze(real, 0)\n",
    "    if pred.shape[0] == 1:\n",
    "        pred = np.squeeze(pred, 0)   \n",
    "    return np.sum(real==pred)/real.shape[0]\n",
    "\n",
    "\n",
    "def segment_of_overlap(ss_ref_str, ss_pred_str):\n",
    "    ss_ref = get_segments(ss_ref_str)\n",
    "    ss_pred = get_segments(ss_pred_str)\n",
    "    val_total = 0\n",
    "    N_total = 0\n",
    "    for k in ss_ref.keys():\n",
    "        subsum_k = 0\n",
    "        N_k = 0\n",
    "        for i in ss_ref[k]:\n",
    "            l_s1 = len(i[1])\n",
    "            N_k += l_s1\n",
    "            for j in ss_pred[k]:\n",
    "                l_s2 = len(j[1])\n",
    "                minov = len(np.intersect1d(i[1], j[1]))\n",
    "                if minov > 0:\n",
    "                    maxov = len(np.union1d(i[1], j[1]))\n",
    "                    delta = np.min([maxov-minov, minov, np.floor(l_s1/2), np.floor(l_s2/2)])\n",
    "                    value = l_s1*(minov+delta)/maxov\n",
    "                    subsum_k += value\n",
    "        N_total += N_k\n",
    "        val_total += subsum_k\n",
    "    sov = val_total/N_total\n",
    "    return sov\n",
    "\n",
    "def get_segments(ss_str):\n",
    "    ss_strs = [\"\".join(grp) for val, grp in itertools.groupby(ss_str)]\n",
    "    idx_lens = []\n",
    "    idx_start = 0\n",
    "    for i in ss_strs:\n",
    "        idx_lens.append(np.arange(idx_start, idx_start+len(i)))\n",
    "        idx_start += len(i)\n",
    "    segment_types = {'E':[], 'H':[], '-':[]}\n",
    "    for i in range(len(ss_strs)):\n",
    "        segment_types[ss_strs[i][0]].append([ss_strs[i], idx_lens[i]])\n",
    "    return segment_types\n",
    "\n",
    "def ints_to_symbols1d(ss_arr, map_dict=pos_ss_dict):\n",
    "    if len(ss_arr.shape) > 1:\n",
    "        for i,j in enumerate(ss_arr.shape):\n",
    "            if j == 1:\n",
    "                ss_arr = np.squeeze(ss_arr, i)\n",
    "    return \"\".join([map_dict[i] for i in ss_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6982074128625934"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracies = [q3_acc(i,j) for i,j in zip(validation_preds, validation_reals)]\n",
    "np.mean(val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = [np.apply_along_axis(np.argmax, 1, net(i[0]).detach().numpy()) for i in testloader]\n",
    "test_reals = [np.apply_along_axis(np.argmax, 1, i[1].detach().numpy()) for i in testloader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7024543451507796"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracies_fcn = [q3_acc(i,j) for i,j in zip(test_preds, test_reals)]\n",
    "np.mean(test_accuracies_fcn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_psipred(prot_id, letter_to_number=ss_id_dict):\n",
    "    ss = ''\n",
    "    with open('/Users/Deathvoodoo/big_folders_docs/ss_pred/ss_predictions_psipred/{}.horiz'.format(prot_id)) as input:\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            line = line.split()\n",
    "            if len(line)>0:\n",
    "                if line[0] == 'Pred:' and len(line)>1:\n",
    "                    ss += line[1]\n",
    "\n",
    "    ss = ss.replace('C', '-') # hyphens should be equivalent to coils\n",
    "    ss = np.array([letter_to_number[i] for i in ss])\n",
    "    return ss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "psipred_preds = [parse_psipred(i) for i in test_ids_filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[i.shape[0]/np.squeeze(j, 0).shape[0] for i,j in zip(psipred_preds, test_reals)] # sanity check for correct order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "psipred_acc = [q3_acc(i,j) for i,j in zip(psipred_preds, test_reals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7255188449781512"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(psipred_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check segment of overlap score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_str_fcn = [ints_to_symbols1d(i) for i in test_preds]\n",
    "test_preds_str_psipred = [ints_to_symbols1d(i) for i in psipred_preds]\n",
    "test_reals_str = [ints_to_symbols1d(i) for i in test_reals] # same as grabbing strings directly from the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN SOV:  0.7672537488189217\n",
      "psipred SOV:  0.7850154998573716\n"
     ]
    }
   ],
   "source": [
    "test_sovs_fcn = [segment_of_overlap(i, j) for i,j in zip(test_preds_str_fcn, test_reals_str)]\n",
    "test_sovs_psipred = [segment_of_overlap(i, j) for i,j in zip(test_preds_str_psipred, test_reals_str)]\n",
    "\n",
    "print('FCN SOV: ', np.mean(test_sovs_fcn))\n",
    "print('psipred SOV: ', np.mean(test_sovs_psipred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bitdff059f72f8b417fb86b0d43a0194990"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
