{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make a simple protein secondary structure predictor for predicting one of the three classes: coil, helix and beta sheet. Whereas popular tools like [psipred](http://bioinf.cs.ucl.ac.uk/psipred/) use neural networks on a window of amino acids, we will instead use a fully convolutional neural network to input the whole sequence. \n",
    "<br>\n",
    "Thus, the input will be sequences encoded as $N*C*L$ where $C$ = 20 (number of amino acids), $L$ = length and $N$ is the size of the minibatch. The output will have the same dimensions except only three channels, corresponding to one of the three classes. \n",
    "<br>Basically, we'll be doing image segmentation on the protein sequences with a neural network analogous to the [U-NET](https://en.wikipedia.org/wiki/U-Net) architecture, but a bit simpler.\n",
    "<br>\n",
    "<br> \n",
    "we will evaluate the quality of the predictions with the Q3 accuracy (basically accuracy across all residues) and the segment of overlap score. The segment of overlap score takes into account how much entire segments with the same secondary structure type overlap between the reference and the prediction, as opposed to the identity of individual amino acids. \n",
    "<br>\n",
    "In order to have an idea of how well we're doing, we will compare our results with the results obtained with psipred, although ideally we're not supposed to use single sequences for psipred, but a multiple sequence alignment.\n",
    "<br>\n",
    "<br>\n",
    "For training, validation and testing, we will use the data that was used to train the [jpred method](http://www.compbio.dundee.ac.uk/jpred4/about_RETR_JNetv231_details.shtml) as it is easily available and fulfills criteria such as a lack of structural/sequence homology between training and test set, which would lead to a biased evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load packages and data and define a few helper variables and functions. We also filter the proteins for proteins that are missing residues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = np.loadtxt('train_names', dtype='str')\n",
    "test_ids = np.loadtxt('test_names', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fasta_dssp(DATA_PATH, prot_ids):\n",
    "    items = {}\n",
    "    for i in prot_ids:\n",
    "        with open(DATA_PATH+i+\".fasta\") as input:\n",
    "            seq = ''\n",
    "            lines = input.readlines()\n",
    "            for line in lines:\n",
    "                if line[0] != '>':\n",
    "                    seq += line.strip()\n",
    "        with open(DATA_PATH+i+\".dssp\") as input:\n",
    "            ss = ''\n",
    "            lines = input.readlines()\n",
    "            for line in lines:\n",
    "                if line[0] != '>':\n",
    "                    ss += line.strip()\n",
    "\n",
    "        items[i] = {'seq':seq, 'ss':ss}\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_items = parse_fasta_dssp('data/training/', train_ids)\n",
    "test_items = parse_fasta_dssp('data/blind/', test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_id_dict = {'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, 'I': 7,\n",
    "              'K': 8, 'L': 9, 'M': 10, 'N': 11, 'P': 12, 'Q': 13, 'R': 14, \n",
    "              'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19}\n",
    "\n",
    "pos_aa_dict = {j:i for i,j in aa_id_dict.items()}\n",
    "\n",
    "ss_id_dict = {'H':0, 'E':1, '-':2}\n",
    "\n",
    "pos_ss_dict = {j:i for i,j in ss_id_dict.items()}\n",
    "\n",
    "def aa_to_onehot(aa_str, aa_to_nr=aa_id_dict, mask=None):\n",
    "    \"\"\"\n",
    "    Onehot encode an amino acid string using a letter to number dictionary.\n",
    "    The mask (from proteinnet files) is used to remove residues missing atoms from the primary sequence.\n",
    "    \"\"\"\n",
    "    if mask!=None:\n",
    "        mask_ind = np.asarray([x=='+' for x in mask])*1\n",
    "        mask_ind = np.nonzero(mask_ind)\n",
    "        aa_str = \"\".join([aa_str[x] for x in mask_ind[0]]) # the mask indices are a list in a list\n",
    "    init_array = np.zeros( (len(aa_to_nr.keys()), len(aa_str)) )\n",
    "    for i,j in enumerate(aa_str):\n",
    "        init_array[aa_to_nr[j], i] = 1\n",
    "    return init_array\n",
    "\n",
    "def label_to_index(ss, id_dict):\n",
    "    labels = np.array([id_dict[i] for i in ss])\n",
    "    return(labels)\n",
    "\n",
    "def onehot_to_str(onehot_arr, map_dict=pos_aa_dict):\n",
    "    '''Helper function to recover aa sequence from onehot encoding\n",
    "        input must be aa*N numpy array'''\n",
    "    aas = []\n",
    "    N = onehot_arr.shape[1]\n",
    "    for i in range(N):\n",
    "        pos = np.where(onehot_arr[:, i]>0)[0]\n",
    "        aas.append(map_dict[int(pos)])\n",
    "    return \"\".join(aas)\n",
    "\n",
    "def filter_proteins(prot_id, seq, allowed_symbols):\n",
    "    allowed = True\n",
    "    for i in seq:\n",
    "        if i not in allowed_symbols:\n",
    "            allowed = False\n",
    "    return allowed\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inds_filt = np.array([filter_proteins(i, training_items[i]['seq'], aa_id_dict.keys()) for i in train_ids])\n",
    "test_inds_filt = np.array([filter_proteins(i, test_items[i]['seq'], aa_id_dict.keys()) for i in test_ids])\n",
    "\n",
    "train_ids_filt = train_ids[train_inds_filt]\n",
    "test_ids_filt = test_ids[test_inds_filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N train proteins:  (1345,)\n",
      "N test proteins:  (149,)\n"
     ]
    }
   ],
   "source": [
    "print('N train proteins: ',train_ids_filt.shape)\n",
    "print('N test proteins: ',test_ids_filt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_ids_filt:\n",
    "    training_items[i]['seq_1h'] = aa_to_onehot(training_items[i]['seq'], aa_id_dict)[np.newaxis, :, :]\n",
    "    training_items[i]['ss_idx'] = label_to_index(training_items[i]['ss'], ss_id_dict)[np.newaxis, :]\n",
    "    \n",
    "for i in test_ids_filt:\n",
    "    test_items[i]['seq_1h'] = aa_to_onehot(test_items[i]['seq'], aa_id_dict)[np.newaxis, :, :]\n",
    "    test_items[i]['ss_idx'] = label_to_index(test_items[i]['ss'], ss_id_dict)[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(678)\n",
    "inds_perm = np.random.permutation(len(train_ids_filt))\n",
    "val_prots = train_ids_filt[inds_perm[0:int(np.floor(len(inds_perm)*0.2))]]\n",
    "train_prots = train_ids_filt[inds_perm[int(np.floor(len(inds_perm)*0.2)):]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define a custom collate function for our pytorch dataset dataloader, since we do not have everything put into one big tensor. In this collate function we will pad each minibatch to the longest sequence in the minibatch and then put it in one tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class proteindataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, seqs, ss):\n",
    "        self.sequences = seqs\n",
    "        self.ss = ss\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.sequences[idx], self.ss[idx]]\n",
    "\n",
    "def protein_collate(batch):\n",
    "    seqs = [item[0] for item in batch]\n",
    "    ss = [item[1] for item in batch]\n",
    "    max_len = max([x.shape[2] for x in seqs])\n",
    "    for i in range(len(batch)):\n",
    "        curr_len = seqs[i].shape[2]\n",
    "        seq_padded = np.pad(seqs[i], ((0,0 ), (0,0), (0,max_len-curr_len)), constant_values = 0)\n",
    "        ss_padded = np.pad(ss[i], ((0,0 ), (0,max_len-curr_len)), constant_values = 0)\n",
    "        seqs[i] = torch.tensor(seq_padded).float()\n",
    "        ss[i] = torch.tensor(ss_padded)\n",
    "    seq_tensor = torch.cat(seqs, 0)\n",
    "    ss_tensor = torch.cat(ss, 0)\n",
    "    return [seq_tensor, ss_tensor]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs = [training_items[i]['seq_1h'] for i in train_prots]\n",
    "train_ss = [training_items[i]['ss_idx'] for i in train_prots]\n",
    "\n",
    "val_seqs = [training_items[i]['seq_1h'] for i in val_prots]\n",
    "val_ss = [training_items[i]['ss_idx'] for i in val_prots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = proteindataset(train_seqs, train_ss)\n",
    "val_dataset = proteindataset(val_seqs, val_ss)\n",
    "test_dataset = proteindataset([test_items[i]['seq_1h'] for i in test_items.keys()], [test_items[i]['ss_idx'] for i in test_items.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2, collate_fn=protein_collate)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=4, collate_fn=protein_collate)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=4, collate_fn=protein_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define the neural network now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "kd2 = 3\n",
    "pad2 = int((kd2-1)/2)\n",
    "kd3 = 5\n",
    "pad3 = int((kd3-1)/2)\n",
    "kd4 = 7\n",
    "pad4 = int((kd4-1)/2)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv0 = nn.Conv1d(20, 32, kernel_size=1)\n",
    "        self.conv0_bn = torch.nn.BatchNorm1d(32)\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=kd2, padding=pad2) # down\n",
    "        self.conv1_bn = torch.nn.BatchNorm1d(32)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=kd3, padding=pad3) # down \n",
    "        self.conv2_bn = torch.nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 64, kernel_size=kd4, padding=pad4) # down\n",
    "        self.conv3_bn = torch.nn.BatchNorm1d(64)\n",
    "        self.conv4 = nn.Conv1d(64, 128, kernel_size=1)\n",
    "        self.conv4_bn = torch.nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.deconv1 = nn.ConvTranspose1d(in_channels=128, out_channels=64, kernel_size=kd4, padding=pad4) # up\n",
    "        self.deconv1_bn = torch.nn.BatchNorm1d(64)\n",
    "        self.conv5 = nn.Conv1d(64, 64, 1)\n",
    "        self.conv5_bn = torch.nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.deconv2 = nn.ConvTranspose1d(in_channels=128, out_channels=64, kernel_size=kd3, padding=pad3) # up\n",
    "        self.deconv2_bn = torch.nn.BatchNorm1d(64)\n",
    "        self.conv6 = nn.Conv1d(64, 64, 1)\n",
    "        self.conv6_bn = torch.nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.deconv3 = nn.ConvTranspose1d(in_channels=96, out_channels=32, kernel_size=kd2, padding=pad2) # up\n",
    "        self.deconv3_bn = torch.nn.BatchNorm1d(32)\n",
    "        self.conv7 = nn.Conv1d(32, 16, (1))\n",
    "        self.conv7_bn = torch.nn.BatchNorm1d(16)\n",
    "        self.conv8 = nn.Conv1d(16, 3, 1)\n",
    "        self.conv8_bn = torch.nn.BatchNorm1d(3)\n",
    "        self.conv9 = nn.Conv1d(3, 3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv0_out = F.relu(self.conv0_bn(self.conv0(x)))\n",
    "        conv1_out = F.relu(self.conv1_bn(self.conv1(conv0_out)))\n",
    "        conv2_out = F.relu(self.conv2_bn(self.conv2(conv1_out)))\n",
    "        conv3_out = F.relu(self.conv3_bn(self.conv3(conv2_out)))\n",
    "        conv4_out = F.relu(self.conv4_bn(self.conv4(conv3_out)))\n",
    "\n",
    "        deconv1_out = F.relu(self.deconv1_bn(self.deconv1(conv4_out)))\n",
    "        conv5_out = F.relu(self.conv5_bn(self.conv5(deconv1_out)))\n",
    "        \n",
    "        deconv2_input = torch.cat((conv2_out, deconv1_out), 1)  \n",
    "        deconv2_out = F.relu(self.deconv2_bn(self.deconv2(deconv2_input)))\n",
    "        conv6_out = F.relu(self.conv6_bn(self.conv6(deconv2_out)))\n",
    "        \n",
    "        deconv3_input = torch.cat((conv1_out, deconv2_out), 1)\n",
    "        deconv3_out = F.relu(self.deconv3_bn(self.deconv3(deconv3_input)))\n",
    "        conv7_out = F.relu(self.conv7_bn(self.conv7(deconv3_out)))\n",
    "        conv8_out = F.relu(self.conv8(conv7_out))\n",
    "        conv9_out = self.conv9(conv8_out)\n",
    "        return conv9_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the network. We will use regular cross entropy and the adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iteration: 88] training loss: 0.8652211159802554, validation_loss: 0.9955412521681375\n",
      "epoch: 0, iteration: 177] training loss: 0.6834594714507628, validation_loss: 0.8808755037066659\n",
      "new best validation loss, saving..\n",
      "epoch: 0, iteration: 266] training loss: 0.5911952692471193, validation_loss: 0.8670906047838776\n",
      "new best validation loss, saving..\n",
      "epoch: 1, iteration: 88] training loss: 0.5326066298431225, validation_loss: 0.7746358149335282\n",
      "new best validation loss, saving..\n",
      "epoch: 1, iteration: 177] training loss: 0.5027740805336599, validation_loss: 0.7732474192367613\n",
      "new best validation loss, saving..\n",
      "epoch: 1, iteration: 266] training loss: 0.4820474423049541, validation_loss: 0.8476267709607972\n",
      "epoch: 2, iteration: 88] training loss: 0.458459628097127, validation_loss: 0.7612017991374418\n",
      "new best validation loss, saving..\n",
      "epoch: 2, iteration: 177] training loss: 0.4793350160791633, validation_loss: 0.780261761415403\n",
      "epoch: 2, iteration: 266] training loss: 0.48884712075919245, validation_loss: 0.7448255490636301\n",
      "new best validation loss, saving..\n",
      "epoch: 3, iteration: 88] training loss: 0.4497634768486023, validation_loss: 0.7510550635897981\n",
      "epoch: 3, iteration: 177] training loss: 0.4470250861028607, validation_loss: 0.7152365001825597\n",
      "new best validation loss, saving..\n",
      "epoch: 3, iteration: 266] training loss: 0.46344702766182716, validation_loss: 0.711489733267008\n",
      "new best validation loss, saving..\n",
      "epoch: 4, iteration: 88] training loss: 0.42730114048116663, validation_loss: 0.7134631781329895\n",
      "epoch: 4, iteration: 177] training loss: 0.4394695038875837, validation_loss: 0.7058428671058669\n",
      "new best validation loss, saving..\n",
      "epoch: 4, iteration: 266] training loss: 0.4426356128762277, validation_loss: 0.7085341221781023\n",
      "epoch: 5, iteration: 88] training loss: 0.43179568815767094, validation_loss: 0.7026075820497422\n",
      "new best validation loss, saving..\n",
      "epoch: 5, iteration: 177] training loss: 0.4302118683464072, validation_loss: 0.6961606023036857\n",
      "new best validation loss, saving..\n",
      "epoch: 5, iteration: 266] training loss: 0.4169436555899931, validation_loss: 0.7091076100404379\n",
      "epoch: 6, iteration: 88] training loss: 0.4077015472262093, validation_loss: 0.7007426637256015\n",
      "epoch: 6, iteration: 177] training loss: 0.41598156111293966, validation_loss: 0.7127520475245768\n",
      "epoch: 6, iteration: 266] training loss: 0.4342781345496017, validation_loss: 0.7168331963311343\n",
      "epoch: 7, iteration: 88] training loss: 0.3854916557837068, validation_loss: 0.7094972187369294\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "prints_per_epoch = 3\n",
    "\n",
    "verbose_k = np.floor(len(trainloader)/prints_per_epoch)\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "iterations = []\n",
    "best_loss = None\n",
    "patience_val = 5\n",
    "patience_counter = patience_val\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        sequence, true_angles = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        predicted_angles = net(sequence)\n",
    "\n",
    "        loss = criterion(predicted_angles, true_angles)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # adding to running loss, we will output this at every verbose_k\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % verbose_k == 0:\n",
    "            if patience_counter < 1:\n",
    "                break\n",
    "            train_losses.append(running_loss/verbose_k)\n",
    "            true_iter = len(trainloader)*epoch + i\n",
    "            iterations.append(true_iter)\n",
    "            net.eval()\n",
    "            validation_loss = 0\n",
    "            for j in valloader:\n",
    "                pred_k = net(j[0])\n",
    "                loss_k = criterion(pred_k, j[1]).item()\n",
    "                validation_loss += loss_k/len(val_seqs)\n",
    "            val_losses.append(validation_loss)\n",
    "            net.train()\n",
    "            print('epoch: {}, iteration: {}] training loss: {}, validation_loss: {}'.format(\n",
    "                epoch, i, running_loss/verbose_k, validation_loss))\n",
    "\n",
    "            if best_loss == None:\n",
    "                best_loss = validation_loss\n",
    "            else:\n",
    "                if validation_loss <= min(val_losses):\n",
    "                    patience_counter = patience_val\n",
    "                    print('new best validation loss, saving..')\n",
    "                    best_loss = validation_loss\n",
    "                    torch.save(net.state_dict(), 'fcn_mle.pt')\n",
    "                else:\n",
    "                    patience_counter -= 1\n",
    "            \n",
    "\n",
    "            running_loss = 0.0\n",
    "            \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss_values = {'train_loss':train_losses, 'val_loss':val_losses,'iterations':iterations}\n",
    "training_loss_values_file = open('training_loss_values.pickle', 'wb')\n",
    "pickle.dump(training_loss_values, training_loss_values_file)\n",
    "training_loss_values_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the loss curve and also generate predictions for the validation set with the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load('fcn_mle.pt'))\n",
    "\n",
    "net.eval()\n",
    "\n",
    "validation_preds = [np.apply_along_axis(np.argmax, 1, net(i[0]).detach().numpy()) for i in valloader]\n",
    "validation_reals = val_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(iterations, train_losses, label='train loss')\n",
    "plt.scatter(iterations, val_losses, label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate the Q3 accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_acc(real, pred):\n",
    "    if real.shape[0] == 1:\n",
    "        real = np.squeeze(real, 0)\n",
    "    if pred.shape[0] == 1:\n",
    "        pred = np.squeeze(pred, 0)   \n",
    "    return np.sum(real==pred)/real.shape[0]\n",
    "\n",
    "\n",
    "def segment_of_overlap(ss_ref_str, ss_pred_str):\n",
    "    ss_ref = get_segments(ss_ref_str)\n",
    "    ss_pred = get_segments(ss_pred_str)\n",
    "    val_total = 0\n",
    "    N_total = 0\n",
    "    for k in ss_ref.keys():\n",
    "        subsum_k = 0\n",
    "        N_k = 0\n",
    "        for i in ss_ref[k]:\n",
    "            l_s1 = len(i[1])\n",
    "            N_k += l_s1\n",
    "            for j in ss_pred[k]:\n",
    "                l_s2 = len(j[1])\n",
    "                minov = len(np.intersect1d(i[1], j[1]))\n",
    "                if minov > 0:\n",
    "                    maxov = len(np.union1d(i[1], j[1]))\n",
    "                    delta = np.min([maxov-minov, minov, np.floor(l_s1/2), np.floor(l_s2/2)])\n",
    "                    value = l_s1*(minov+delta)/maxov\n",
    "                    subsum_k += value\n",
    "        N_total += N_k\n",
    "        val_total += subsum_k\n",
    "    sov = val_total/N_total\n",
    "    return sov\n",
    "\n",
    "def get_segments(ss_str):\n",
    "    ss_strs = [\"\".join(grp) for val, grp in itertools.groupby(ss_str)]\n",
    "    idx_lens = []\n",
    "    idx_start = 0\n",
    "    for i in ss_strs:\n",
    "        idx_lens.append(np.arange(idx_start, idx_start+len(i)))\n",
    "        idx_start += len(i)\n",
    "    segment_types = {'E':[], 'H':[], '-':[]}\n",
    "    for i in range(len(ss_strs)):\n",
    "        segment_types[ss_strs[i][0]].append([ss_strs[i], idx_lens[i]])\n",
    "    return segment_types\n",
    "\n",
    "def ints_to_symbols1d(ss_arr, map_dict=pos_ss_dict):\n",
    "    if len(ss_arr.shape) > 1:\n",
    "        for i,j in enumerate(ss_arr.shape):\n",
    "            if j == 1:\n",
    "                ss_arr = np.squeeze(ss_arr, i)\n",
    "    return \"\".join([map_dict[i] for i in ss_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN validation Q3 accuracy:  0.7064434326552966\n"
     ]
    }
   ],
   "source": [
    "val_accuracies = [q3_acc(i,j) for i,j in zip(validation_preds, validation_reals)]\n",
    "print('FCN validation Q3 accuracy: ', np.mean(val_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're not really going to search for any hyperparameters, we can just evaluate the test set and also compare with psipred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = [np.apply_along_axis(np.argmax, 1, net(i[0]).detach().numpy()) for i in testloader]\n",
    "test_reals = [i[1].numpy() for i in testloader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_psipred(prot_id, letter_to_number=ss_id_dict, PSIPRED_PREDS_PATH='ss_predictions_psipred/'):\n",
    "    ss = ''\n",
    "    with open('{}{}.horiz'.format(PSIPRED_PREDS_PATH, prot_id)) as input:\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            line = line.split()\n",
    "            if len(line)>0:\n",
    "                if line[0] == 'Pred:' and len(line)>1:\n",
    "                    ss += line[1]\n",
    "\n",
    "    ss = ss.replace('C', '-') # hyphens should be equivalent to coils\n",
    "    ss = np.array([letter_to_number[i] for i in ss])\n",
    "    return ss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN Q3 accuracy on test set:  0.7122077952783453\n",
      "psipred Q3 accuracy on test set:  0.7255188449781512\n"
     ]
    }
   ],
   "source": [
    "test_accuracies_fcn = [q3_acc(i,j) for i,j in zip(test_preds, test_reals)]\n",
    "\n",
    "\n",
    "psipred_preds = [parse_psipred(i) for i in test_ids_filt]\n",
    "psipred_acc = [q3_acc(i,j) for i,j in zip(psipred_preds, test_reals)]\n",
    "\n",
    "print('FCN Q3 accuracy on test set: ',np.mean(test_accuracies_fcn))\n",
    "print('psipred Q3 accuracy on test set: ',np.mean(psipred_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check segment of overlap score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_str_fcn = [ints_to_symbols1d(i) for i in test_preds]\n",
    "test_preds_str_psipred = [ints_to_symbols1d(i) for i in psipred_preds]\n",
    "test_reals_str = [ints_to_symbols1d(i) for i in test_reals] # same as grabbing strings directly from the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN SOV on test set:  0.7715468536989495\n",
      "psipred SOV on test set:  0.7850154998573716\n"
     ]
    }
   ],
   "source": [
    "test_sovs_fcn = [segment_of_overlap(i, j) for i,j in zip(test_preds_str_fcn, test_reals_str)]\n",
    "test_sovs_psipred = [segment_of_overlap(i, j) for i,j in zip(test_preds_str_psipred, test_reals_str)]\n",
    "\n",
    "print('FCN SOV on test set: ', np.mean(test_sovs_fcn))\n",
    "print('psipred SOV on test set: ', np.mean(test_sovs_psipred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bitdff059f72f8b417fb86b0d43a0194990"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
