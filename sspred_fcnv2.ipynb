{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make a simple protein secondary structure predictor for predicting one of the three classes: coil, helix and beta sheet. Whereas popular tools like [psipred](http://bioinf.cs.ucl.ac.uk/psipred/) use neural networks on a window of amino acids, we will instead use a fully convolutional neural network to input the whole sequence. \n",
    "<brb>\n",
    "Thus, the input will be sequences encoded as $N*C*L$ where $C$ = 20 (number of amino acids), $L$ = length and $N$ is the size of the minibatch, and the output will have the same dimensions except only three channels, corresponding to one of the three classes. Basically, we'll be doing image segmentation on the protein sequences.\n",
    "<br>\n",
    "<br> \n",
    "we will evaluate the quality of the predictions with the Q3 accuracy (basically accuracy across all residues) and the segment of overlap score. The segment of overlap score takes into account how much entire segments with the same secondary structure type overlap between the reference and the prediction, as opposed to the identity of individual amino acids. \n",
    "<br>In order to have an idea of how well we're doing, we will compare our results with the results obtained with psipred, although ideally we're not supposed to use single sequences for psipred, but a multiple sequence alignment.\n",
    "<br>\n",
    "<br> For training, validation and testing, we will use the data that was used to train the [jpred method](http://www.compbio.dundee.ac.uk/jpred4/about_RETR_JNetv231_details.shtml) as it is easily available and fulfills criteria such as a lack of structural/sequence homology between training and test set, which would lead to a biased evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = np.loadtxt('train_names', dtype='str')\n",
    "test_ids = np.loadtxt('test_names', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_items={}\n",
    "for i in train_ids:\n",
    "    with open('data/training/'+i+\".fasta\") as input:\n",
    "        seq = ''\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            if line[0] != '>':\n",
    "                seq += line.strip()\n",
    "    with open('data/training/'+i+\".dssp\") as input:\n",
    "        ss = ''\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            if line[0] != '>':\n",
    "                ss += line.strip()\n",
    "            \n",
    "    training_items[i] = {'seq':seq, 'ss':ss}\n",
    "    \n",
    "    \n",
    "test_items={}\n",
    "for i in test_ids:\n",
    "    with open('data/blind/'+i+\".fasta\") as input:\n",
    "        seq = ''\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            if line[0] != '>':\n",
    "                seq += line.strip()\n",
    "    with open('data/blind/'+i+\".dssp\") as input:\n",
    "        ss = ''\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            if line[0] != '>':\n",
    "                ss += line.strip()\n",
    "            \n",
    "    test_items[i] = {'seq':seq, 'ss':ss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_id_dict = {'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, 'I': 7,\n",
    "              'K': 8, 'L': 9, 'M': 10, 'N': 11, 'P': 12, 'Q': 13, 'R': 14, \n",
    "              'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19}\n",
    "\n",
    "pos_aa_dict = {j:i for i,j in aa_id_dict.items()}\n",
    "\n",
    "ss_id_dict = {'H':0, 'E':1, '-':2}\n",
    "\n",
    "pos_ss_dict = {j:i for i,j in ss_id_dict.items()}\n",
    "\n",
    "def aa_to_onehot(aa_str, aa_to_nr=aa_id_dict, mask=None):\n",
    "    \"\"\"\n",
    "    Onehot encode an amino acid string using a letter to number dictionary.\n",
    "    The mask (from proteinnet files) is used to remove residues missing atoms from the primary sequence.\n",
    "    \"\"\"\n",
    "    if mask!=None:\n",
    "        mask_ind = np.asarray([x=='+' for x in mask])*1\n",
    "        mask_ind = np.nonzero(mask_ind)\n",
    "        aa_str = \"\".join([aa_str[x] for x in mask_ind[0]]) # the mask indices are a list in a list\n",
    "    init_array = np.zeros( (len(aa_to_nr.keys()), len(aa_str)) )\n",
    "    for i,j in enumerate(aa_str):\n",
    "        init_array[aa_to_nr[j], i] = 1\n",
    "    return init_array\n",
    "\n",
    "def label_to_index(ss, id_dict):\n",
    "    labels = np.array([id_dict[i] for i in ss])\n",
    "    return(labels)\n",
    "\n",
    "def onehot_to_str(onehot_arr, map_dict=pos_aa_dict):\n",
    "    '''Helper function to recover aa sequence from onehot encoding\n",
    "        input must be aa*N numpy array'''\n",
    "    aas = []\n",
    "    N = onehot_arr.shape[1]\n",
    "    for i in range(N):\n",
    "        pos = np.where(onehot_arr[:, i]>0)[0]\n",
    "        aas.append(map_dict[int(pos)])\n",
    "    return \"\".join(aas)\n",
    "\n",
    "def filter_proteins(prot_id, seq, allowed_symbols):\n",
    "    allowed = True\n",
    "    for i in seq:\n",
    "        if i not in allowed_symbols:\n",
    "            allowed = False\n",
    "    return allowed\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inds_filt = np.array([filter_proteins(i, training_items[i]['seq'], aa_id_dict.keys()) for i in train_ids])\n",
    "test_inds_filt = np.array([filter_proteins(i, test_items[i]['seq'], aa_id_dict.keys()) for i in test_ids])\n",
    "\n",
    "train_ids_filt = train_ids[train_inds_filt]\n",
    "test_ids_filt = test_ids[test_inds_filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1345,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids_filt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_ids_filt:\n",
    "    training_items[i]['seq_1h'] = aa_to_onehot(training_items[i]['seq'], aa_id_dict)[np.newaxis, :, :]\n",
    "    training_items[i]['ss_idx'] = label_to_index(training_items[i]['ss'], ss_id_dict)[np.newaxis, :]\n",
    "    \n",
    "for i in test_ids_filt:\n",
    "    test_items[i]['seq_1h'] = aa_to_onehot(test_items[i]['seq'], aa_id_dict)[np.newaxis, :, :]\n",
    "    test_items[i]['ss_idx'] = label_to_index(test_items[i]['ss'], ss_id_dict)[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(678)\n",
    "inds_perm = np.random.permutation(len(train_ids_filt))\n",
    "val_prots = train_ids_filt[inds_perm[0:int(np.floor(len(inds_perm)*0.2))]]\n",
    "train_prots = train_ids_filt[inds_perm[int(np.floor(len(inds_perm)*0.2)):]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class proteindataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, seqs, ss):\n",
    "        self.sequences = seqs\n",
    "        self.ss = ss\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.sequences[idx], self.ss[idx]]\n",
    "\n",
    "def protein_collate(batch):\n",
    "    seqs = [item[0] for item in batch]\n",
    "    ss = [item[1] for item in batch]\n",
    "    max_len = max([x.shape[2] for x in seqs])\n",
    "    for i in range(len(batch)):\n",
    "        curr_len = seqs[i].shape[2]\n",
    "        seq_padded = np.pad(seqs[i], ((0,0 ), (0,0), (0,max_len-curr_len)), constant_values = 0)\n",
    "        ss_padded = np.pad(ss[i], ((0,0 ), (0,max_len-curr_len)), constant_values = 0)\n",
    "        seqs[i] = torch.tensor(seq_padded).float()\n",
    "        ss[i] = torch.tensor(ss_padded)\n",
    "    seq_tensor = torch.cat(seqs, 0)\n",
    "    ss_tensor = torch.cat(ss, 0)\n",
    "    return [seq_tensor, ss_tensor]\n",
    "\n",
    "def protein_collate2(batch):\n",
    "    seqs = [item[0] for item in batch]\n",
    "    ss = [item[1] for item in batch]\n",
    "    max_len = max([x.shape[2] for x in seqs])\n",
    "    for i in range(len(batch)):\n",
    "        curr_len = seqs[i].shape[2]\n",
    "        seq_padded = np.pad(seqs[i], ((0,0 ), (0,0), (0,max_len-curr_len)), constant_values = 0)\n",
    "        ss_padded = np.pad(ss[i], ((0,0 ), (0,max_len-curr_len)), constant_values = 0)\n",
    "        seqs[i] = torch.tensor(seq_padded).float()\n",
    "        ss[i] = torch.tensor(ss_padded).float()\n",
    "    seq_tensor = torch.cat(seqs, 0)\n",
    "    ss_tensor = torch.cat(ss, 0)\n",
    "    return [seq_tensor, ss_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs = [training_items[i]['seq_1h'] for i in train_prots]\n",
    "train_ss = [training_items[i]['ss_idx'] for i in train_prots]\n",
    "\n",
    "val_seqs = [training_items[i]['seq_1h'] for i in val_prots]\n",
    "val_ss = [training_items[i]['ss_idx'] for i in val_prots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = proteindataset(train_seqs, train_ss)\n",
    "val_dataset = proteindataset(val_seqs, val_ss)\n",
    "test_dataset = proteindataset([test_items[i]['seq_1h'] for i in test_items.keys()], [test_items[i]['ss_idx'] for i in test_items.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 89)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ss[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2, collate_fn=protein_collate)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=4, collate_fn=protein_collate)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=4, collate_fn=protein_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "kd2 = 3\n",
    "pad2 = int((kd2-1)/2)\n",
    "kd3 = 5\n",
    "pad3 = int((kd3-1)/2)\n",
    "kd4 = 7\n",
    "pad4 = int((kd4-1)/2)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv0 = nn.Conv1d(20, 32, kernel_size=1)\n",
    "        self.conv0_bn = torch.nn.BatchNorm1d(32)\n",
    "        self.conv1 = nn.Conv1d(32, 32, kernel_size=kd2, padding=pad2) # down\n",
    "        self.conv1_bn = torch.nn.BatchNorm1d(32)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=kd3, padding=pad3) # down \n",
    "        self.conv2_bn = torch.nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 64, kernel_size=kd4, padding=pad4) # down\n",
    "        self.conv3_bn = torch.nn.BatchNorm1d(64)\n",
    "        self.conv4 = nn.Conv1d(64, 128, kernel_size=1)\n",
    "        self.conv4_bn = torch.nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.deconv1 = nn.ConvTranspose1d(in_channels=128, out_channels=64, kernel_size=kd4, padding=pad4) # up\n",
    "        self.deconv1_bn = torch.nn.BatchNorm1d(64)\n",
    "        self.conv5 = nn.Conv1d(64, 64, 1)\n",
    "        self.conv5_bn = torch.nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.deconv2 = nn.ConvTranspose1d(in_channels=128, out_channels=64, kernel_size=kd3, padding=pad3) # up\n",
    "        self.deconv2_bn = torch.nn.BatchNorm1d(64)\n",
    "        self.conv6 = nn.Conv1d(64, 64, 1)\n",
    "        self.conv6_bn = torch.nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.deconv3 = nn.ConvTranspose1d(in_channels=96, out_channels=32, kernel_size=kd2, padding=pad2) # up\n",
    "        self.deconv3_bn = torch.nn.BatchNorm1d(32)\n",
    "        self.conv7 = nn.Conv1d(32, 16, (1))\n",
    "        self.conv7_bn = torch.nn.BatchNorm1d(16)\n",
    "        self.conv8 = nn.Conv1d(16, 3, 1)\n",
    "        self.conv8_bn = torch.nn.BatchNorm1d(3)\n",
    "        self.conv9 = nn.Conv1d(3, 3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv0_out = F.relu(self.conv0_bn(self.conv0(x)))\n",
    "        conv1_out = F.relu(self.conv1_bn(self.conv1(conv0_out)))\n",
    "        conv2_out = F.relu(self.conv2_bn(self.conv2(conv1_out)))\n",
    "        conv3_out = F.relu(self.conv3_bn(self.conv3(conv2_out)))\n",
    "        conv4_out = F.relu(self.conv4_bn(self.conv4(conv3_out)))\n",
    "\n",
    "        deconv1_out = F.relu(self.deconv1_bn(self.deconv1(conv4_out)))\n",
    "        conv5_out = F.relu(self.conv5_bn(self.conv5(deconv1_out)))\n",
    "        \n",
    "        deconv2_input = torch.cat((conv2_out, deconv1_out), 1)  \n",
    "        deconv2_out = F.relu(self.deconv2_bn(self.deconv2(deconv2_input)))\n",
    "        conv6_out = F.relu(self.conv6_bn(self.conv6(deconv2_out)))\n",
    "        \n",
    "        deconv3_input = torch.cat((conv1_out, deconv2_out), 1)\n",
    "        deconv3_out = F.relu(self.deconv3_bn(self.deconv3(deconv3_input)))\n",
    "        conv7_out = F.relu(self.conv7_bn(self.conv7(deconv3_out)))\n",
    "        conv8_out = F.relu(self.conv8(conv7_out))\n",
    "        conv9_out = self.conv9(conv8_out)\n",
    "        return conv9_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the network. Since we output a matrix of one-hot encoded classes for each protein instead of a single scalar, we can no longer use the default cross-entropy loss provided by pytorch and must use the 'dice loss' instead.\n",
    "<br>\n",
    "Fortunately, other people [(e.g. this person)](https://github.com/hubutui/DiceLoss-PyTorch/blob/master/loss.py) have already implemented such loss functions and we can simply copy paste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iteration: 88] training loss: 1.0252212172143915, validation_loss: 1.0301439864041637\n",
      "epoch: 0, iteration: 177] training loss: 0.8106757107745396, validation_loss: 1.0093996821726121\n",
      "new best validation loss, saving..\n",
      "epoch: 0, iteration: 266] training loss: 0.6372557714414061, validation_loss: 0.9261904307900758\n",
      "new best validation loss, saving..\n",
      "epoch: 1, iteration: 88] training loss: 0.591760841983088, validation_loss: 0.8835781216621402\n",
      "new best validation loss, saving..\n",
      "epoch: 1, iteration: 177] training loss: 0.5725573542412747, validation_loss: 0.835026384286277\n",
      "new best validation loss, saving..\n",
      "epoch: 1, iteration: 266] training loss: 0.542045656214939, validation_loss: 0.8261121370756929\n",
      "new best validation loss, saving..\n",
      "epoch: 2, iteration: 88] training loss: 0.519281091315023, validation_loss: 0.8024451082302295\n",
      "new best validation loss, saving..\n",
      "epoch: 2, iteration: 177] training loss: 0.5077718355682459, validation_loss: 0.7675220797939376\n",
      "new best validation loss, saving..\n",
      "epoch: 2, iteration: 266] training loss: 0.5034816874546951, validation_loss: 0.7678797261644027\n",
      "epoch: 3, iteration: 88] training loss: 0.4596507057045283, validation_loss: 0.7393287333857173\n",
      "new best validation loss, saving..\n",
      "epoch: 3, iteration: 177] training loss: 0.47252591674247485, validation_loss: 0.7251663568073045\n",
      "new best validation loss, saving..\n",
      "epoch: 3, iteration: 266] training loss: 0.4593597647179379, validation_loss: 0.7286452933536585\n",
      "epoch: 4, iteration: 88] training loss: 0.44145162654726694, validation_loss: 0.7105776673134374\n",
      "new best validation loss, saving..\n",
      "epoch: 4, iteration: 177] training loss: 0.4422935023066703, validation_loss: 0.7154743337941437\n",
      "epoch: 4, iteration: 266] training loss: 0.4410355553198396, validation_loss: 0.7103835547058994\n",
      "new best validation loss, saving..\n",
      "epoch: 5, iteration: 88] training loss: 0.4242551320054558, validation_loss: 0.7035321375029683\n",
      "new best validation loss, saving..\n",
      "epoch: 5, iteration: 177] training loss: 0.42521276802159425, validation_loss: 0.7351214429259744\n",
      "epoch: 5, iteration: 266] training loss: 0.42699258297346954, validation_loss: 0.7091337878907922\n",
      "epoch: 6, iteration: 88] training loss: 0.42341928284489705, validation_loss: 0.7044478792240183\n",
      "epoch: 6, iteration: 177] training loss: 0.4144487879919202, validation_loss: 0.7642865478992467\n",
      "epoch: 6, iteration: 266] training loss: 0.4290773808286431, validation_loss: 0.7183794355414616\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "prints_per_epoch = 3\n",
    "\n",
    "verbose_k = np.floor(len(trainloader)/prints_per_epoch)\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "iterations = []\n",
    "best_loss = None\n",
    "patience_val = 5\n",
    "patience_counter = patience_val\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        sequence, true_angles = data\n",
    "        #print(sequence.shape, true_angles.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        predicted_angles = net(sequence)\n",
    "\n",
    "        loss = criterion(predicted_angles, true_angles)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # adding to running loss, we will output this at every verbose_k\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % verbose_k == 0:\n",
    "            if patience_counter < 1:\n",
    "                break\n",
    "            train_losses.append(running_loss/verbose_k)\n",
    "            true_iter = len(trainloader)*epoch + i\n",
    "            iterations.append(true_iter)\n",
    "            net.eval()\n",
    "            validation_loss = 0\n",
    "            for j in valloader:\n",
    "                pred_k = net(j[0])\n",
    "                loss_k = criterion(pred_k, j[1]).item()\n",
    "                validation_loss += loss_k/len(val_seqs)\n",
    "            val_losses.append(validation_loss)\n",
    "            net.train()\n",
    "            print('epoch: {}, iteration: {}] training loss: {}, validation_loss: {}'.format(\n",
    "                epoch, i, running_loss/verbose_k, validation_loss))\n",
    "\n",
    "            if best_loss == None:\n",
    "                best_loss = validation_loss\n",
    "            else:\n",
    "                if validation_loss <= min(val_losses):\n",
    "                    patience_counter = patience_val\n",
    "                    print('new best validation loss, saving..')\n",
    "                    best_loss = validation_loss\n",
    "                    torch.save(net.state_dict(), 'fcn_mle.pt')\n",
    "                else:\n",
    "                    patience_counter -= 1\n",
    "            \n",
    "\n",
    "            running_loss = 0.0\n",
    "            \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the loss curve and also generate predictions for the validation set with the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load('/Users/Deathvoodoo/big_folders_docs/ss_pred/fcn_mle.pt'))\n",
    "\n",
    "net.eval()\n",
    "\n",
    "validation_preds = [np.apply_along_axis(np.argmax, 1, net(i[0]).detach().numpy()) for i in valloader]\n",
    "validation_reals = val_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(iterations, train_losses, label='train loss')\n",
    "plt.scatter(iterations, val_losses, label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate the Q3 accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_acc(real, pred):\n",
    "    if real.shape[0] == 1:\n",
    "        real = np.squeeze(real, 0)\n",
    "    if pred.shape[0] == 1:\n",
    "        pred = np.squeeze(pred, 0)   \n",
    "    return np.sum(real==pred)/real.shape[0]\n",
    "\n",
    "\n",
    "def segment_of_overlap(ss_ref_str, ss_pred_str):\n",
    "    ss_ref = get_segments(ss_ref_str)\n",
    "    ss_pred = get_segments(ss_pred_str)\n",
    "    val_total = 0\n",
    "    N_total = 0\n",
    "    for k in ss_ref.keys():\n",
    "        subsum_k = 0\n",
    "        N_k = 0\n",
    "        for i in ss_ref[k]:\n",
    "            l_s1 = len(i[1])\n",
    "            N_k += l_s1\n",
    "            for j in ss_pred[k]:\n",
    "                l_s2 = len(j[1])\n",
    "                minov = len(np.intersect1d(i[1], j[1]))\n",
    "                if minov > 0:\n",
    "                    maxov = len(np.union1d(i[1], j[1]))\n",
    "                    delta = np.min([maxov-minov, minov, np.floor(l_s1/2), np.floor(l_s2/2)])\n",
    "                    value = l_s1*(minov+delta)/maxov\n",
    "                    subsum_k += value\n",
    "        N_total += N_k\n",
    "        val_total += subsum_k\n",
    "    sov = val_total/N_total\n",
    "    return sov\n",
    "\n",
    "def get_segments(ss_str):\n",
    "    ss_strs = [\"\".join(grp) for val, grp in itertools.groupby(ss_str)]\n",
    "    idx_lens = []\n",
    "    idx_start = 0\n",
    "    for i in ss_strs:\n",
    "        idx_lens.append(np.arange(idx_start, idx_start+len(i)))\n",
    "        idx_start += len(i)\n",
    "    segment_types = {'E':[], 'H':[], '-':[]}\n",
    "    for i in range(len(ss_strs)):\n",
    "        segment_types[ss_strs[i][0]].append([ss_strs[i], idx_lens[i]])\n",
    "    return segment_types\n",
    "\n",
    "def ints_to_symbols1d(ss_arr, map_dict=pos_ss_dict):\n",
    "    if len(ss_arr.shape) > 1:\n",
    "        for i,j in enumerate(ss_arr.shape):\n",
    "            if j == 1:\n",
    "                ss_arr = np.squeeze(ss_arr, i)\n",
    "    return \"\".join([map_dict[i] for i in ss_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN validation Q3 accuracy:  0.6991616287529621\n"
     ]
    }
   ],
   "source": [
    "val_accuracies = [q3_acc(i,j) for i,j in zip(validation_preds, validation_reals)]\n",
    "print('FCN validation Q3 accuracy: ', np.mean(val_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're not really going to search for any hyperparameters, we can just evaluate the test set and also compare with psipred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = [np.apply_along_axis(np.argmax, 1, net(i[0]).detach().numpy()) for i in testloader]\n",
    "test_reals = [i[1].numpy() for i in testloader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_psipred(prot_id, letter_to_number=ss_id_dict):\n",
    "    ss = ''\n",
    "    with open('/Users/Deathvoodoo/big_folders_docs/ss_pred/ss_predictions_psipred/{}.horiz'.format(prot_id)) as input:\n",
    "        lines = input.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            line = line.split()\n",
    "            if len(line)>0:\n",
    "                if line[0] == 'Pred:' and len(line)>1:\n",
    "                    ss += line[1]\n",
    "\n",
    "    ss = ss.replace('C', '-') # hyphens should be equivalent to coils\n",
    "    ss = np.array([letter_to_number[i] for i in ss])\n",
    "    return ss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN Q3 accuracy on test set:  0.703634580452644\n",
      "psipred Q3 accuracy on test set:  0.7255188449781512\n"
     ]
    }
   ],
   "source": [
    "test_accuracies_fcn = [q3_acc(i,j) for i,j in zip(test_preds, test_reals)]\n",
    "\n",
    "\n",
    "psipred_preds = [parse_psipred(i) for i in test_ids_filt]\n",
    "psipred_acc = [q3_acc(i,j) for i,j in zip(psipred_preds, test_reals)]\n",
    "\n",
    "print('FCN Q3 accuracy on test set: ',np.mean(test_accuracies_fcn))\n",
    "print('psipred Q3 accuracy on test set: ',np.mean(psipred_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check segment of overlap score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_str_fcn = [ints_to_symbols1d(i) for i in test_preds]\n",
    "test_preds_str_psipred = [ints_to_symbols1d(i) for i in psipred_preds]\n",
    "test_reals_str = [ints_to_symbols1d(i) for i in test_reals] # same as grabbing strings directly from the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN SOV on test set:  0.7841545813866221\n",
      "psipred SOV on test set:  0.7850154998573716\n"
     ]
    }
   ],
   "source": [
    "test_sovs_fcn = [segment_of_overlap(i, j) for i,j in zip(test_preds_str_fcn, test_reals_str)]\n",
    "test_sovs_psipred = [segment_of_overlap(i, j) for i,j in zip(test_preds_str_psipred, test_reals_str)]\n",
    "\n",
    "print('FCN SOV on test set: ', np.mean(test_sovs_fcn))\n",
    "print('psipred SOV on test set: ', np.mean(test_sovs_psipred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bitdff059f72f8b417fb86b0d43a0194990"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
